{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeFgwuUlW8HIem6pZlwbEr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Building makemore pt.4: becoming a backprop ninja\n","\n","Current deep learning frameworks allow us to call `loss.backwards()` to perform automatic backpropagation. **The problem with Backpropagation is that it is a leaky abstraction**. It could be a problem not understanding how backpropagation works when trying to debug your neural network. So let's implement backpropagation from scratch to get a better understanding on how it works.\n","\n","[Blog post: Yes you should understand backpropagation](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b)"],"metadata":{"id":"7-6FZOkKA3_R"}},{"cell_type":"markdown","source":["We will still use the same model from *makemore part 3*"],"metadata":{"id":"yzmC2D__DR3d"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"gmlhCnQaAxRK","executionInfo":{"status":"ok","timestamp":1679641892986,"user_tz":240,"elapsed":3866,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt # for making figures\n","%matplotlib inline"]},{"cell_type":"code","source":["!curl -O https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JT3R9NqfEJVw","executionInfo":{"status":"ok","timestamp":1679641893644,"user_tz":240,"elapsed":661,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"04f308e6-23e8-453b-e3c1-677f07cf5ff7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  222k  100  222k    0     0   828k      0 --:--:-- --:--:-- --:--:--  828k\n"]}]},{"cell_type":"code","source":["# read in all the words\n","words = open('names.txt', 'r').read().splitlines()\n","print(len(words))\n","print(max(len(w) for w in words))\n","print(words[:8])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8HbqzU6DxnN","executionInfo":{"status":"ok","timestamp":1679641893645,"user_tz":240,"elapsed":6,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"45c811b7-8cc0-4fd4-b2c4-d9e984214ab1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["32033\n","15\n","['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"]}]},{"cell_type":"code","source":["# build the vocabulary of characters and mappings to/from integers\n","chars = sorted(list(set(''.join(words))))\n","stoi = {s:i+1 for i,s in enumerate(chars)}\n","stoi['.'] = 0\n","itos = {i:s for s,i in stoi.items()}\n","vocab_size = len(itos)\n","print(itos)\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rFjCOD_wDyir","executionInfo":{"status":"ok","timestamp":1679641893645,"user_tz":240,"elapsed":4,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"cdc5f5d8-1e75-448a-b06f-b3230ea3db82"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n","27\n"]}]},{"cell_type":"code","source":["# build the dataset\n","block_size = 3 # context length: how many characters do we take to predict the next one?\n","\n","def build_dataset(words):  \n","  X, Y = [], []\n","  \n","  for w in words:\n","    context = [0] * block_size\n","    for ch in w + '.':\n","      ix = stoi[ch]\n","      X.append(context)\n","      Y.append(ix)\n","      context = context[1:] + [ix] # crop and append\n","\n","  X = torch.tensor(X)\n","  Y = torch.tensor(Y)\n","  print(X.shape, Y.shape)\n","  return X, Y\n","\n","import random\n","random.seed(42)\n","random.shuffle(words)\n","n1 = int(0.8*len(words))\n","n2 = int(0.9*len(words))\n","\n","Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n","Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n","Xte,  Yte  = build_dataset(words[n2:])     # 10%"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALwWMJuADzxl","executionInfo":{"status":"ok","timestamp":1679641895132,"user_tz":240,"elapsed":1489,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"6d6cb73d-8d80-42cf-a6cc-33ac57183442"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([182625, 3]) torch.Size([182625])\n","torch.Size([22655, 3]) torch.Size([22655])\n","torch.Size([22866, 3]) torch.Size([22866])\n"]}]},{"cell_type":"code","source":["# utility function we will use later when comparing manual gradients to PyTorch gradients\n","def cmp(s, dt, t):\n","  ex = torch.all(dt == t.grad).item()\n","  app = torch.allclose(dt, t.grad)\n","  maxdiff = (dt - t.grad).abs().max().item()\n","  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"],"metadata":{"id":"ksllbie3FCNA","executionInfo":{"status":"ok","timestamp":1679641895132,"user_tz":240,"elapsed":4,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["n_embd = 10 # the dimensionality of the character embedding vectors\n","n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n","\n","g = torch.Generator().manual_seed(2147483647) # for reproducibility\n","C  = torch.randn((vocab_size, n_embd),            generator=g)\n","# Layer 1\n","W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n","b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n","# Layer 2\n","W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n","b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n","# BatchNorm parameters\n","bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n","bnbias = torch.randn((1, n_hidden))*0.1\n","\n","# Note: I am initializating many of these parameters in non-standard ways\n","# because sometimes initializating with e.g. all zeros could mask an incorrect\n","# implementation of the backward pass.\n","\n","parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n","print(sum(p.nelement() for p in parameters)) # number of parameters in total\n","for p in parameters:\n","  p.requires_grad = True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lwwpSjrFDX3","executionInfo":{"status":"ok","timestamp":1679641895133,"user_tz":240,"elapsed":5,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"44d492da-a26a-49e8-dda2-25fca7b163ff"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["4137\n"]}]},{"cell_type":"code","source":["batch_size = 32\n","n = batch_size # a shorter variable also, for convenience\n","# construct a minibatch\n","ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n","Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"],"metadata":{"id":"h_LxA1oIG3SS","executionInfo":{"status":"ok","timestamp":1679641895133,"user_tz":240,"elapsed":3,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n","emb = C[Xb] # embed the characters into vectors\n","embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n","# Linear layer 1\n","hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n","# BatchNorm layer\n","bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n","bndiff = hprebn - bnmeani\n","bndiff2 = bndiff**2\n","bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n","bnvar_inv = (bnvar + 1e-5)**-0.5\n","bnraw = bndiff * bnvar_inv\n","hpreact = bngain * bnraw + bnbias\n","# Non-linearity\n","h = torch.tanh(hpreact) # hidden layer\n","# Linear layer 2\n","logits = h @ W2 + b2 # output layer\n","# cross entropy loss (same as F.cross_entropy(logits, Yb))\n","logit_maxes = logits.max(1, keepdim=True).values\n","norm_logits = logits - logit_maxes # subtract max for numerical stability\n","counts = norm_logits.exp()\n","counts_sum = counts.sum(1, keepdims=True)\n","counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n","probs = counts * counts_sum_inv\n","logprobs = probs.log()\n","loss = -logprobs[range(n), Yb].mean()\n","\n","# PyTorch backward pass\n","for p in parameters:\n","  p.grad = None\n","for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n","          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n","         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n","         embcat, emb]:\n","  t.retain_grad()\n","loss.backward()\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwNFBRhTG4re","executionInfo":{"status":"ok","timestamp":1679641895344,"user_tz":240,"elapsed":213,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"81f4caa3-75ce-4421-9290-4a9018cb6e8e"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.3764, grad_fn=<NegBackward0>)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Exercise 1: backprop through the whole thing manually, \n","# backpropagating through exactly all of the variables \n","# as they are defined in the forward pass above, one by one\n","\n","dlogprobs = torch.zeros_like(logprobs)\n","dlogprobs[range(n), Yb] = -1.0/n\n","dprobs = torch.zeros_like(probs)\n","dprobs = (1.0/probs) * dlogprobs\n","dcounts_sum_inv = torch.zeros_like(counts_sum_inv)\n","dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n","dcounts = torch.zeros_like(counts)\n","dcounts = counts_sum_inv * dprobs\n","dcounts_sum = torch.zeros_like(counts_sum)\n","dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n","dcounts += dcounts_sum\n","dnorm_logits = counts * dcounts\n","dlogits = dnorm_logits.clone()\n","dlogit_maxes = (-1 * dnorm_logits).sum(1, keepdim=True)\n","dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes # this is simply 1 * dlogits_maxes\n","dh = dlogits @ W2.T\n","dW2 = h.T @ dlogits \n","db2 = dlogits.sum(0)\n","dhpreact = (1.0 - h**2) * dh\n","dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n","dbnbias = (1 * dhpreact).sum(0, keepdim=True)\n","dbnraw = bngain * dhpreact\n","dbndiff = bnvar_inv * dbnraw\n","dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n","dbnvar = -.5*(bnvar + 1e-5)**-1.5 * dbnvar_inv\n","dbndiff2 = 1/(n-1)*torch.ones_like(bndiff) * dbnvar\n","dbndiff += (2 * bndiff) * dbndiff2\n","dbnmeani = -dbndiff.sum(0)\n","dhprebn = dbndiff.clone() \n","dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n","dembcat = dhprebn @ W1.T\n","dW1 = embcat.T @ dhprebn\n","db1 = dhprebn.sum(0)\n","demb = dembcat.view(emb.shape)\n","dC = torch.zeros_like(C)\n","for k in range(Xb.shape[0]):\n","  for j in range(Xb.shape[1]):\n","    ix = Xb[k, j]\n","    dC[ix] += demb[k, j]\n","    \n","cmp('logprobs', dlogprobs, logprobs)\n","cmp('probs', dprobs, probs)\n","cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n","cmp('counts_sum', dcounts_sum, counts_sum)\n","cmp('counts', dcounts, counts)\n","cmp('norm_logits', dnorm_logits, norm_logits)\n","cmp('logit_maxes', dlogit_maxes, logit_maxes)\n","cmp('logits', dlogits, logits)\n","cmp('h', dh, h)\n","cmp('W2', dW2, W2)\n","cmp('b2', db2, b2)\n","cmp('hpreact', dhpreact, hpreact)\n","cmp('bngain', dbngain, bngain)\n","cmp('bnbias', dbnbias, bnbias)\n","cmp('bnraw', dbnraw, bnraw)\n","cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n","cmp('bnvar', dbnvar, bnvar)\n","cmp('bndiff2', dbndiff2, bndiff2)\n","cmp('bndiff', dbndiff, bndiff)\n","cmp('bnmeani', dbnmeani, bnmeani)\n","cmp('hprebn', dhprebn, hprebn)\n","cmp('embcat', dembcat, embcat)\n","cmp('W1', dW1, W1)\n","cmp('b1', db1, b1)\n","cmp('emb', demb, emb)\n","cmp('C', dC, C)"],"metadata":{"id":"RwGUlukgG9rZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679641895569,"user_tz":240,"elapsed":226,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"8b5a38ea-a1cc-4093-c4f5-53bdc398d988"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n","probs           | exact: True  | approximate: True  | maxdiff: 0.0\n","counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n","counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n","counts          | exact: True  | approximate: True  | maxdiff: 0.0\n","norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n","logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n","logits          | exact: True  | approximate: True  | maxdiff: 0.0\n","h               | exact: True  | approximate: True  | maxdiff: 0.0\n","W2              | exact: True  | approximate: True  | maxdiff: 0.0\n","b2              | exact: True  | approximate: True  | maxdiff: 0.0\n","hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bngain          | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n","bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n","bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n","bnvar           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bndiff2         | exact: False | approximate: True  | maxdiff: 1.4551915228366852e-11\n","bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","bnmeani         | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n","hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n","embcat          | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n","W1              | exact: False | approximate: True  | maxdiff: 4.190951585769653e-09\n","b1              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n","emb             | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n","C               | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"]}]},{"cell_type":"code","source":["# Exercise 2: backprop through cross_entropy but all in one go\n","# to complete this challenge look at the mathematical expression of the loss,\n","# take the derivative, simplify the expression, and just write it out\n","\n","# forward pass\n","\n","# before:\n","# logit_maxes = logits.max(1, keepdim=True).values\n","# norm_logits = logits - logit_maxes # subtract max for numerical stability\n","# counts = norm_logits.exp()\n","# counts_sum = counts.sum(1, keepdims=True)\n","# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n","# probs = counts * counts_sum_inv\n","# logprobs = probs.log()\n","# loss = -logprobs[range(n), Yb].mean()\n","\n","# now:\n","loss_fast = F.cross_entropy(logits, Yb)\n","print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"],"metadata":{"id":"6dFIYILi4UhA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679641895569,"user_tz":240,"elapsed":5,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"e891b7c6-c671-4d54-82a6-9fd1ad531ce3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["3.3764219284057617 diff: -2.384185791015625e-07\n"]}]},{"cell_type":"code","source":["# backward pass\n","\n","dlogits = F.softmax(logits, 1)\n","dlogits[range(n), Yb] -= 1\n","dlogits /= n\n","\n","cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpzNURRgk_Cn","executionInfo":{"status":"ok","timestamp":1679641896180,"user_tz":240,"elapsed":613,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"96543518-c62f-4bff-936b-d622b6769652"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["logits          | exact: False | approximate: True  | maxdiff: 7.2177499532699585e-09\n"]}]},{"cell_type":"code","source":["logits.shape, Yb.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrKGjTjZKaNi","executionInfo":{"status":"ok","timestamp":1679641896180,"user_tz":240,"elapsed":12,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"5849908b-cb44-4b93-cb4b-b7e696f5ea28"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32, 27]), torch.Size([32]))"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["F.softmax(logits, 1)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeuSek04dJqx","executionInfo":{"status":"ok","timestamp":1679641896181,"user_tz":240,"elapsed":12,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"8dcac1fe-ed43-4ff5-9059-87339f00c8e3"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0751, 0.0855, 0.0194, 0.0494, 0.0212, 0.0870, 0.0226, 0.0341, 0.0169,\n","        0.0316, 0.0348, 0.0363, 0.0360, 0.0291, 0.0342, 0.0132, 0.0097, 0.0178,\n","        0.0164, 0.0525, 0.0499, 0.0205, 0.0259, 0.0716, 0.0616, 0.0260, 0.0218],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["\n","dlogits[0] * n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F0zQ1SGMdKp5","executionInfo":{"status":"ok","timestamp":1679641896181,"user_tz":240,"elapsed":10,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"76410b53-9d45-4951-9446-264827663855"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.0751,  0.0855,  0.0194,  0.0494,  0.0212,  0.0870,  0.0226,  0.0341,\n","        -0.9831,  0.0316,  0.0348,  0.0363,  0.0360,  0.0291,  0.0342,  0.0132,\n","         0.0097,  0.0178,  0.0164,  0.0525,  0.0499,  0.0205,  0.0259,  0.0716,\n","         0.0616,  0.0260,  0.0218], grad_fn=<MulBackward0>)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["dlogits[0].sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DTU09cJdLeb","executionInfo":{"status":"ok","timestamp":1679641896182,"user_tz":240,"elapsed":9,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"4dfdc026-60f6-4409-e134-7721e9b5e52d"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-7.9162e-09, grad_fn=<SumBackward0>)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["plt.figure(figsize=(4, 4))\n","plt.imshow(dlogits.detach(), cmap='gray')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"V1RdaErYdM8X","executionInfo":{"status":"ok","timestamp":1679641896536,"user_tz":240,"elapsed":361,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"ecd6bdc8-fff6-459e-ed7a-6a11906a3eae"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f530e2012b0>"]},"metadata":{},"execution_count":17},{"output_type":"display_data","data":{"text/plain":["<Figure size 288x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Exercise 3: backprop through batchnorm but all in one go\n","# to complete this challenge look at the mathematical expression of the output of batchnorm,\n","# take the derivative w.r.t. its input, simplify the expression, and just write it out\n","\n","# forward pass\n","\n","# before:\n","# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n","# bndiff = hprebn - bnmeani\n","# bndiff2 = bndiff**2\n","# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n","# bnvar_inv = (bnvar + 1e-5)**-0.5\n","# bnraw = bndiff * bnvar_inv\n","# hpreact = bngain * bnraw + bnbias\n","\n","# now:\n","hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n","print('max diff:', (hpreact_fast - hpreact).abs().max())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsbYAmBrdOkB","executionInfo":{"status":"ok","timestamp":1679641896537,"user_tz":240,"elapsed":11,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"b8891820-a475-4319-b8ca-3271d6c4671e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"]}]},{"cell_type":"code","source":["# backward pass\n","\n","# before we had:\n","# dbnraw = bngain * dhpreact\n","# dbndiff = bnvar_inv * dbnraw\n","# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n","# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n","# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n","# dbndiff += (2*bndiff) * dbndiff2\n","# dhprebn = dbndiff.clone()\n","# dbnmeani = (-dbndiff).sum(0)\n","# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n","\n","# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n","# (you'll also need to use some of the variables from the forward pass up above)\n","\n","dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n","\n","cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpmIaUKxdP3M","executionInfo":{"status":"ok","timestamp":1679641896537,"user_tz":240,"elapsed":8,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"78c43cb2-7b33-4444-ae72-bd53008927c0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"]}]},{"cell_type":"code","source":["dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zOmw34v9dfvh","executionInfo":{"status":"ok","timestamp":1679641973751,"user_tz":240,"elapsed":195,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"5a1228a6-9fe1-4b7f-9f04-3b1ea41573f7"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32, 64]),\n"," torch.Size([1, 64]),\n"," torch.Size([1, 64]),\n"," torch.Size([32, 64]),\n"," torch.Size([64]))"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Exercise 4: putting it all together!\n","# Train the MLP neural net with your own backward pass\n","\n","# init\n","n_embd = 10 # the dimensionality of the character embedding vectors\n","n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n","\n","g = torch.Generator().manual_seed(2147483647) # for reproducibility\n","C  = torch.randn((vocab_size, n_embd),            generator=g)\n","# Layer 1\n","W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n","b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n","# Layer 2\n","W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n","b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n","# BatchNorm parameters\n","bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n","bnbias = torch.randn((1, n_hidden))*0.1\n","\n","parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n","print(sum(p.nelement() for p in parameters)) # number of parameters in total\n","for p in parameters:\n","  p.requires_grad = True\n","\n","# same optimization as last time\n","max_steps = 200000\n","batch_size = 32\n","n = batch_size # convenience\n","lossi = []\n","\n","# use this context manager for efficiency once your backward pass is written (TODO)\n","with torch.no_grad():\n","\n","  # kick off optimization\n","  for i in range(max_steps):\n","\n","    # minibatch construct\n","    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n","    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n","\n","    # forward pass\n","    emb = C[Xb] # embed the characters into vectors\n","    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n","    # Linear layer\n","    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n","    # BatchNorm layer\n","    # -------------------------------------------------------------\n","    bnmean = hprebn.mean(0, keepdim=True)\n","    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n","    bnvar_inv = (bnvar + 1e-5)**-0.5\n","    bnraw = (hprebn - bnmean) * bnvar_inv\n","    hpreact = bngain * bnraw + bnbias\n","    # -------------------------------------------------------------\n","    # Non-linearity\n","    h = torch.tanh(hpreact) # hidden layer\n","    logits = h @ W2 + b2 # output layer\n","    loss = F.cross_entropy(logits, Yb) # loss function\n","\n","    # backward pass\n","    for p in parameters:\n","      p.grad = None\n","    #loss.backward() # use this for correctness comparisons, delete it later!\n","\n","    # manual backprop! #swole_doge_meme\n","    # -----------------\n","    dlogits = F.softmax(logits, 1)\n","    dlogits[range(n), Yb] -= 1\n","    dlogits /= n\n","    # 2nd layer backprop\n","    dh = dlogits @ W2.T\n","    dW2 = h.T @ dlogits\n","    db2 = dlogits.sum(0)\n","    # tanh\n","    dhpreact = (1.0 - h**2) * dh\n","    # batchnorm backprop\n","    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n","    dbnbias = dhpreact.sum(0, keepdim=True)\n","    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n","    # 1st layer\n","    dembcat = dhprebn @ W1.T\n","    dW1 = embcat.T @ dhprebn\n","    db1 = dhprebn.sum(0)\n","    # embedding\n","    demb = dembcat.view(emb.shape)\n","    dC = torch.zeros_like(C)\n","    for k in range(Xb.shape[0]):\n","      for j in range(Xb.shape[1]):\n","        ix = Xb[k,j]\n","        dC[ix] += demb[k,j]\n","    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n","    # -----------------\n","\n","    # update\n","    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n","    for p, grad in zip(parameters, grads):\n","      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n","      p.data += -lr * grad # new way of swole doge TODO: enable\n","\n","    # track stats\n","    if i % 10000 == 0: # print every once in a while\n","      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n","    lossi.append(loss.log10().item())\n","\n","  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n","  #     break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cejdWiuQdh-u","executionInfo":{"status":"ok","timestamp":1679642545793,"user_tz":240,"elapsed":571680,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"82a40d52-4ebd-441e-aa00-e53716548005"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["12297\n","      0/ 200000: 3.7523\n","  10000/ 200000: 2.1716\n","  20000/ 200000: 2.3591\n","  30000/ 200000: 2.5164\n","  40000/ 200000: 1.9565\n","  50000/ 200000: 2.4540\n","  60000/ 200000: 2.3336\n","  70000/ 200000: 2.0675\n","  80000/ 200000: 2.3450\n","  90000/ 200000: 2.1121\n"," 100000/ 200000: 1.9414\n"," 110000/ 200000: 2.3505\n"," 120000/ 200000: 2.0135\n"," 130000/ 200000: 2.4400\n"," 140000/ 200000: 2.3414\n"," 150000/ 200000: 2.2154\n"," 160000/ 200000: 2.0218\n"," 170000/ 200000: 1.8217\n"," 180000/ 200000: 1.9985\n"," 190000/ 200000: 1.8617\n"]}]},{"cell_type":"code","source":["# useful for checking your gradients\n","# for p,g in zip(parameters, grads):\n","#   cmp(str(tuple(p.shape)), g, p)"],"metadata":{"id":"ef43wlvUdj_V","executionInfo":{"status":"ok","timestamp":1679642545794,"user_tz":240,"elapsed":3,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# calibrate the batch norm at the end of training\n","\n","with torch.no_grad():\n","  # pass the training set through\n","  emb = C[Xtr]\n","  embcat = emb.view(emb.shape[0], -1)\n","  hpreact = embcat @ W1 + b1\n","  # measure the mean/std over the entire training set\n","  bnmean = hpreact.mean(0, keepdim=True)\n","  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"],"metadata":{"id":"vV5uCmbXdlAP","executionInfo":{"status":"ok","timestamp":1679642547465,"user_tz":240,"elapsed":1673,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# evaluate train and val loss\n","\n","@torch.no_grad() # this decorator disables gradient tracking\n","def split_loss(split):\n","  x,y = {\n","    'train': (Xtr, Ytr),\n","    'val': (Xdev, Ydev),\n","    'test': (Xte, Yte),\n","  }[split]\n","  emb = C[x] # (N, block_size, n_embd)\n","  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n","  hpreact = embcat @ W1 + b1\n","  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n","  h = torch.tanh(hpreact) # (N, n_hidden)\n","  logits = h @ W2 + b2 # (N, vocab_size)\n","  loss = F.cross_entropy(logits, y)\n","  print(split, loss.item())\n","\n","split_loss('train')\n","split_loss('val')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1fapOWMdl4X","executionInfo":{"status":"ok","timestamp":1679642550716,"user_tz":240,"elapsed":3252,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"9c7f07c3-c952-4f92-dc97-d64e3c3c8a84"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["train 2.072545289993286\n","val 2.1097967624664307\n"]}]},{"cell_type":"code","source":["# sample from the model\n","g = torch.Generator().manual_seed(2147483647 + 10)\n","\n","for _ in range(20):\n","    \n","    out = []\n","    context = [0] * block_size # initialize with all ...\n","    while True:\n","      # ------------\n","      # forward pass:\n","      # Embedding\n","      emb = C[torch.tensor([context])] # (1,block_size,d)      \n","      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n","      hpreact = embcat @ W1 + b1\n","      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n","      h = torch.tanh(hpreact) # (N, n_hidden)\n","      logits = h @ W2 + b2 # (N, vocab_size)\n","      # ------------\n","      # Sample\n","      probs = F.softmax(logits, dim=1)\n","      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n","      context = context[1:] + [ix]\n","      out.append(ix)\n","      if ix == 0:\n","        break\n","    \n","    print(''.join(itos[i] for i in out))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_dl0eLvddnZI","executionInfo":{"status":"ok","timestamp":1679642551404,"user_tz":240,"elapsed":690,"user":{"displayName":"Rodrigo Romero","userId":"02145397962148961639"}},"outputId":"3beb68f1-f10a-46df-9129-31f12dd14e57"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["carla.\n","fate.\n","harlin.\n","mri.\n","reity.\n","skaessa.\n","jazhnen.\n","den.\n","arcie.\n","qui.\n","ner.\n","kiah.\n","maiivon.\n","leigh.\n","ham.\n","joce.\n","quint.\n","shoine.\n","liveni.\n","wavero.\n"]}]}]}